{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser as fp\n",
    "import newspaper\n",
    "import json\n",
    "\n",
    "from newspaper import Article\n",
    "from datetime import datetime\n",
    "from time import mktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limit for number of articles to download\n",
    "LIMIT = 600\n",
    "data = {}\n",
    "data['newspapers'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping news articles from 25 news sites, where last 5 it's fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the JSON files with news sites\n",
    "with open('NewsPapers.json') as data_file:\n",
    "    companies = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading articles from  newyorktimes_business\n",
      "10 articles downloaded from newyorktimes_business , url:  https://www.nytimes.com/2020/05/10/business/economy/coronavirus-tyson-plant-iowa.html\n",
      "20 articles downloaded from newyorktimes_business , url:  https://www.nytimes.com/2020/05/08/business/economy/tesla-coronavirus-factory-alameda.html\n",
      "30 articles downloaded from newyorktimes_business , url:  https://www.nytimes.com/2020/05/08/your-money/coronavirus-debt-collection.html\n",
      "40 articles downloaded from newyorktimes_business , url:  https://www.nytimes.com/2020/05/07/health/coronavirus-vaccine-moderna.html\n",
      "50 articles downloaded from newyorktimes_business , url:  https://www.nytimes.com/2020/05/07/business/media/advertising-coronavirus-news.html\n",
      "Downloading articles from  newyorktimes_science\n",
      "10 articles downloaded from newyorktimes_science , url:  https://www.nytimes.com/2020/05/10/world/coronavirus-news.html\n",
      "20 articles downloaded from newyorktimes_science , url:  https://www.nytimes.com/2020/05/08/health/virus-summer-pandemic.html\n",
      "30 articles downloaded from newyorktimes_science , url:  https://www.nytimes.com/2020/05/07/world/coronavirus-news.html\n",
      "40 articles downloaded from newyorktimes_science , url:  https://www.nytimes.com/2020/05/05/science/paul-marks-dead.html\n",
      "50 articles downloaded from newyorktimes_science , url:  https://www.nytimes.com/2020/05/04/climate/heat-temperatures-climate-change.html\n",
      "Downloading articles from  newyorktimes_technology\n",
      "10 articles downloaded from newyorktimes_technology , url:  https://www.nytimes.com/2020/05/07/world/europe/uk-coronavirus-contact-tracing.html\n",
      "20 articles downloaded from newyorktimes_technology , url:  https://www.nytimes.com/2020/05/05/us/barack-obama-virtual-commencement-speech-coronavirus.html\n",
      "Downloading articles from  cnnmoney\n",
      "Downloading articles from  marketwatch_newsletters\n",
      "Downloading articles from  marketwatch_stories\n",
      "10 articles downloaded from marketwatch_stories , url:  http://www.marketwatch.com/news/story.asp?guid=%7B66F5501A-913E-11EA-9208-AF2E6FA5B5BC%7D&siteid=rss&rss=1\n",
      "Downloading articles from  cnbc_top_news\n",
      "10 articles downloaded from cnbc_top_news , url:  https://www.cnbc.com/2020/05/09/eric-schmidt-is-reportedly-no-longer-an-advisor-to-the-company.html\n",
      "20 articles downloaded from cnbc_top_news , url:  https://www.cnbc.com/2020/05/09/-newsrecapandbestreads.html\n",
      "30 articles downloaded from cnbc_top_news , url:  https://www.cnbc.com/2020/05/08/when-will-restaurants-and-bars-reopen-heres-what-experts-are-saying.html\n",
      "Downloading articles from  cnbc_investing\n",
      "10 articles downloaded from cnbc_investing , url:  https://www.cnbc.com/2020/05/06/jim-cramer-plant-based-meat-is-a-trend-investors-should-not-ignore.html\n",
      "20 articles downloaded from cnbc_investing , url:  https://www.cnbc.com/2020/05/02/buffett-on-why-he-hasnt-made-any-big-investments-we-dont-see-anything-that-attractive.html\n",
      "30 articles downloaded from cnbc_investing , url:  https://www.cnbc.com/2020/04/30/op-ed-the-market-comeback-seems-callous-but-investors-are-betting-on-a-bright-post-crisis-future.html\n",
      "Downloading articles from  marketwatch\n",
      "10 articles downloaded from marketwatch , url:  https://www.theguardian.com/society/2020/may/10/diary-entries-will-chart-the-mood-of-britain-in-coronavirus-quarantine\n",
      "20 articles downloaded from marketwatch , url:  https://www.theguardian.com/global/2020/may/10/the-new-rules-to-life-in-lockdown-science-non-expert-observations\n",
      "30 articles downloaded from marketwatch , url:  https://www.theguardian.com/uk-news/2020/may/09/harry-dunns-family-call-for-parliamentary-inquiry-into-death\n",
      "40 articles downloaded from marketwatch , url:  https://www.theguardian.com/uk-news/2020/may/10/hebridean-island-divided-tamsin-calidas-memoir\n",
      "50 articles downloaded from marketwatch , url:  https://www.theguardian.com/sport/2020/may/10/justin-gaethje-shocks-tony-ferguson-with-ko-at-controversial-ufc-249\n",
      "60 articles downloaded from marketwatch , url:  https://www.theguardian.com/world/video/2020/may/06/how-coronavirus-is-dividing-india-video-explainer\n",
      "70 articles downloaded from marketwatch , url:  https://www.theguardian.com/world/2020/may/09/back-to-work-capacity-of-transport-network-will-be-down-by-90\n",
      "80 articles downloaded from marketwatch , url:  https://www.theguardian.com/world/2020/may/09/imf-warns-of-further-drop-in-global-growth-due-to-covid-19\n",
      "90 articles downloaded from marketwatch , url:  https://www.theguardian.com/full-of-beanz/2020/feb/13/no-posh-bread-no-fancy-cheese-and-certainly-no-mayo-the-seven-unwritten-rules-of-eating-baked-beans\n",
      "100 articles downloaded from marketwatch , url:  https://www.theguardian.com/world/2020/mar/23/uk-healthcare-workers-share-your-photo-videos-and-audio-of-working-against-coronavirus\n",
      "110 articles downloaded from marketwatch , url:  https://www.theguardian.com/artanddesign/gallery/2020/may/09/its-a-gas-gas-gas-remnants-of-our-industrial-past-in-pictures\n",
      "Downloading articles from  fox_business_latest_headlines\n",
      "10 articles downloaded from fox_business_latest_headlines , url:  https://www.foxnews.com/health/global-coronavirus-infections-top-4-million-us-death-toll-passes-78000\n",
      "Downloading articles from  fox_business_opinion\n",
      "10 articles downloaded from fox_business_opinion , url:  http://feeds.foxnews.com/~r/foxnews/opinion/~3/fhebqJWeyvk/mothers-day-2020-tv-moms-life-stories-jim-daly\n",
      "20 articles downloaded from fox_business_opinion , url:  http://feeds.foxnews.com/~r/foxnews/opinion/~3/qFjVrCd8IVs/curt-levey-ed-dept-wants-students-accused-of-sexual-misconduct-to-have-rights-joe-biden-wants-for-himself\n",
      "Downloading articles from  entrepreneur_latest\n",
      "10 articles downloaded from entrepreneur_latest , url:  http://feedproxy.google.com/~r/entrepreneur/latest/~3/i5eJnYR8g7I/350343\n",
      "Downloading articles from  entrepreneur_marketing\n",
      "10 articles downloaded from entrepreneur_marketing , url:  http://feedproxy.google.com/~r/entrepreneur/salesandmarketing/~3/zmpZPiAzQAQ/350035\n",
      "Downloading articles from  reuters_money\n",
      "10 articles downloaded from reuters_money , url:  http://feeds.reuters.com/~r/news/wealth/~3/oEOojfAqlIc/venture-firm-benchmark-raises-new-fund-without-early-uber-investor-source-idUSKCN22501W\n",
      "20 articles downloaded from reuters_money , url:  http://feeds.reuters.com/~r/news/wealth/~3/yJqNoZGpHYM/your-money-get-aid-or-go-bust-small-businesses-face-dilemma-idUSKCN21V1YX\n",
      "Downloading articles from  reuters_science\n",
      "10 articles downloaded from reuters_science , url:  http://feeds.reuters.com/~r/reuters/scienceNews/~3/8jIztqhbTwk/exclusive-trump-administration-drafting-artemis-accords-pact-for-moon-mining-sources-idUSKBN22H2SB\n",
      "20 articles downloaded from reuters_science , url:  http://feeds.reuters.com/~r/reuters/scienceNews/~3/MlCOyqucXYg/moderna-switzerlands-lonza-strike-deal-on-potential-covid-19-vaccine-idUSKBN22D4GM\n",
      "Downloading articles from  sciencedaily\n",
      "10 articles downloaded from sciencedaily , url:  https://www.sciencedaily.com/releases/2020/05/200508145321.htm\n",
      "20 articles downloaded from sciencedaily , url:  https://www.sciencedaily.com/releases/2020/05/200508112901.htm\n",
      "30 articles downloaded from sciencedaily , url:  https://www.sciencedaily.com/releases/2020/05/200507164005.htm\n",
      "40 articles downloaded from sciencedaily , url:  https://www.sciencedaily.com/releases/2020/05/200507131334.htm\n",
      "50 articles downloaded from sciencedaily , url:  https://www.sciencedaily.com/releases/2020/05/200507131223.htm\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "\n",
    "#Iterate through each news company\n",
    "#the company is the name, the value is the dictionary of links\n",
    "for company, value in companies.items():\n",
    "    #If a RSS link is provided in the JSON file, this will be the first choice\n",
    "    #Reason for this is that, RSS feeds often give more consistent and correct data\n",
    "    #If you do not want to scrape from the RSS-feed, just leave the RSS attr empty in the JSON file\n",
    "    if 'rss' in value:\n",
    "        d = fp.parse(value['rss'])\n",
    "        print(\"Downloading articles from \", company)\n",
    "        newsPaper = {\n",
    "            \"rss\": value['rss'],\n",
    "            \"link\": value['link'],\n",
    "            \"articles\": []\n",
    "        }\n",
    "        for entry in d.entries:\n",
    "            #Check if publish date is provided, if no the article is skipped\n",
    "            #This is done to keep consistency in the data and to keep the script from crashing\n",
    "            if hasattr(entry, 'published'):\n",
    "                if count > LIMIT:\n",
    "                    break\n",
    "                article = {}\n",
    "                article['link'] = entry.link\n",
    "                date = entry.published_parsed\n",
    "                article['published'] = datetime.fromtimestamp(mktime(date)).isoformat()\n",
    "                try:\n",
    "                    content = Article(entry.link)\n",
    "                    content.download()\n",
    "                    content.parse()\n",
    "                except Exception as e:\n",
    "                    #If the download for some reason fails (ex. 404) the script will continue downloading next article\n",
    "                    print(e)\n",
    "                    print(\"continuing...\")\n",
    "                    continue\n",
    "                article['title'] = content.title\n",
    "                article['text'] = content.text\n",
    "                article['author'] = content.authors\n",
    "                newsPaper['articles'].append(article)\n",
    "                if count % 10 == 0:\n",
    "                    print(count, \"articles downloaded from\", company, \", url: \", entry.link)\n",
    "                count = count + 1\n",
    "    else:\n",
    "        #This is the fallback method if a RSS-feed link is not provided\n",
    "        #It uses the python newspaper library to extract articles\n",
    "        print(\"Building site for \", company)\n",
    "        paper = newspaper.build(value['link'], memoize_articles=False)\n",
    "        newsPaper = {\n",
    "            \"link\": value['link'],\n",
    "            \"articles\": []\n",
    "        }\n",
    "        noneTypeCount = 0\n",
    "        for content in paper.articles:\n",
    "            if count > LIMIT:\n",
    "                break\n",
    "            try:\n",
    "                content.download()\n",
    "                content.parse()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"continuing...\")\n",
    "                continue\n",
    "            #Again, for consistency, if there is no found publish date the article will be skipped\n",
    "            #After 10 downloaded articles from the same newspaper without publish date, the company will be skipped\n",
    "            if content.publish_date is None:\n",
    "                print(count, \" Article has date of type None...\")\n",
    "                noneTypeCount = noneTypeCount + 1\n",
    "                if noneTypeCount > 10:\n",
    "                    print(\"Too many noneType dates, aborting...\")\n",
    "                    noneTypeCount = 0\n",
    "                    break\n",
    "                count = count + 1\n",
    "                continue\n",
    "            article = {}\n",
    "            article['title'] = content.title\n",
    "            article['text'] = content.text\n",
    "            article['link'] = content.url\n",
    "            article['published'] = content.publish_date.isoformat()\n",
    "            article['author'] = content.authors\n",
    "            newsPaper['articles'].append(article)\n",
    "            if count % 10 == 0: \n",
    "                print(count, \"articles downloaded from\", company, \" using newspaper, url: \", content.url)\n",
    "            count = count + 1\n",
    "            noneTypeCount = 0\n",
    "    count = 1\n",
    "    data['newspapers'][company] = newsPaper\n",
    "\n",
    "\n",
    "#Save the articles to JSON-file\n",
    "try:\n",
    "    fname = 'scraped_articles.json'\n",
    "    print('saving articles . . . in {}'.format(fname))\n",
    "    with open(fname, 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "except Exception as e: print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
